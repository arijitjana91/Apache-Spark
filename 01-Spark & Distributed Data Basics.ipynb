{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7492f441-8969-4487-bf11-abb17d42c196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 01- Apache Spark & Distributed Data Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8ca1ca6-08e5-4cfb-9bcd-a783c056edcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üåü What is Apache Spark?\n",
    "\n",
    "> Apache Spark is an open-source, distributed computing system designed for fast, large-scale data processing and analytics. It enables in-memory computation, making it significantly faster‚Äîup to 100 times‚Äîthan traditional disk-based systems like Hadoop MapReduce. <p>\n",
    "Spark supports batch, streaming, machine learning (MLlib), and graph processing via APIs in Python, Scala, Java, and R.<p>\n",
    "<b>Note: The project was originally started in 2009 as a research project at UC Berkeley's AMPLab and was open-sourced in 2010.</b>\n",
    "\n",
    "**Simple definition**  \n",
    "Spark lets you process big data across many machines as if you were working on one huge computer.\n",
    "\n",
    "Spark relies on group of machines instead of just one machine, and that group of machines is called as **Cluster -- In Apache Spark it is called as cluster of nodes.**<br>\n",
    "**Node --> Machines**<br>\n",
    "**Cluster --> Group of Machines**<br>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Why Spark exists\n",
    "\n",
    "| Problem           | Pandas / SQL |\n",
    "|-------------------|--------------|\n",
    "| Data too large    | ‚ùå Memory limited |\n",
    "| Slow processing   | ‚ùå Disk-based |\n",
    "| Scalability       | ‚ùå Single machine |\n",
    "\n",
    "**Spark solves all of these.**\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Spark vs Pandas vs SQL (Very Important)\n",
    "\n",
    "| Feature           | Pandas        | SQL          | Spark |\n",
    "|-------------------|---------------|--------------|-------|\n",
    "| Data size         | Small         | Medium       | Very large |\n",
    "| Execution         | Single machine| DB engine    | Cluster |\n",
    "| Speed             | In-memory     | Disk-based   | In-memory + distributed |\n",
    "| Fault tolerance  | ‚ùå            | Partial      | ‚úÖ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae99766d-ce94-4267-8627-709c9cab2b98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üåü Monolithic vs Distributed approaches\n",
    "\n",
    "How big data is handled using **Monolithic vs Distributed** approaches, what each really means, and why distributed wins at scale.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Monolithic Approach (Single-Node / Centralized)\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "## What it is\n",
    "- Entire system runs on one machine\n",
    "- One database, one CPU (or tightly coupled CPUs), one storage\n",
    "- Vertical scaling: bigger machine = more power\n",
    "\n",
    "## Typical Stack\n",
    "\n",
    "- Single SQL Server / Oracle DB\n",
    "- Python / Pandas / R\n",
    "- Traditional ETL tools\n",
    "- On-prem data warehouses\n",
    "\n",
    "**How data is handled**<br>\n",
    "Data ‚Üí Single Server ‚Üí Processing ‚Üí Output<br>\n",
    "\n",
    "## Pros\n",
    "\n",
    "- ‚úÖ Simple architecture\n",
    "- ‚úÖ Easy to develop & debug\n",
    "- ‚úÖ Strong consistency\n",
    "- ‚úÖ Low operational complexity\n",
    "\n",
    "## Cons\n",
    "\n",
    "- ‚ùå Limited scalability (hardware ceiling)\n",
    "- ‚ùå Single point of failure\n",
    "- ‚ùå Very expensive to scale vertically\n",
    "- ‚ùå Poor performance for TB+ data\n",
    "\n",
    "## Best suited for\n",
    "\n",
    "- Small to medium datasets (MBs ‚Üí few GBs)\n",
    "- Low concurrency\n",
    "- Simple analytics\n",
    "- Early-stage systems\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Distributed Approach (Big Data Architecture)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "## What it is\n",
    "- Data & computation spread across many machines\n",
    "- Horizontal scaling: add more nodes\n",
    "- Built for failure (nodes will fail)\n",
    "\n",
    "## Typical Stack\n",
    "- Distributed storage (HDFS, Object Storage)\n",
    "- Distributed compute (Spark, Flink)\n",
    "- Message systems (Kafka, Event Hub)\n",
    "- Cloud-native services\n",
    "\n",
    "**How data is handled**<br>\n",
    "Data ‚Üí Split into chunks ‚Üí Multiple nodes process in parallel ‚Üí Aggregated output\n",
    "\n",
    "## Pros\n",
    "\n",
    "- ‚úÖ Massive scalability (TB ‚Üí PB)\n",
    "- ‚úÖ Fault tolerant\n",
    "- ‚úÖ High throughput\n",
    "- ‚úÖ Cost-effective (commodity hardware / cloud)\n",
    "\n",
    "## Cons\n",
    "\n",
    "- ‚ùå Higher complexity\n",
    "- ‚ùå Network overhead\n",
    "- ‚ùå Eventual consistency models\n",
    "- ‚ùå Debugging is harder\n",
    "\n",
    "## Best suited for\n",
    "- Big data analytics\n",
    "- Streaming data\n",
    "- Machine learning\n",
    "- IoT, logs, telemetry\n",
    "- Enterprise & cloud systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81a70db2-b350-41fa-8f96-8a286b3d26ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üåü Is Apache Spark the only Big Data processing engine that we have ?<br>Scenario before Apache Spark\n",
    "\n",
    "---\n",
    "\n",
    "## **üÜö Apache Spark vs MapReduce (Big Data Processing)**\n",
    "\n",
    "For More info on **Introduction to Bigdata and Hadoop Ecosystem** visit:<br>\n",
    "https://data-flair.training/blogs/hadoop-ecosystem-components/<br>\n",
    "https://faun.pub/introduction-to-bigdata-and-hadoop-ecosystem-1929e59924cf\n",
    "\n",
    "**What is HDFS ?**<br>\n",
    "> Hadoop Distributed File System (HDFS) is a highly fault-tolerant, open-source distributed storage system designed to manage massive datasets (petabytes) across clusters of low-cost, commodity hardware.<p>It uses a master/slave architecture‚Äîconsisting of a NameNode (metadata) and DataNodes (block storage)‚Äîto provide high throughput, data replication, and high availability.<p>\n",
    "**Note: HDFS is the foundational storage layer for the Apache Hadoop ecosystem, widely used for Big Data analytics, AI, and machine learning workloads.**\n",
    "\n",
    "## Key Aspects of HDFS\n",
    "\n",
    "### Architecture\n",
    "![image-7.png](attachment:image-7.png)\n",
    "- HDFS divides large files into smaller blocks (default 128 MB)  \n",
    "- Replicates blocks across multiple nodes to prevent data loss (default: 3 replicas, each at different Data Node.)\n",
    "\n",
    "### HDFS Blocks\n",
    "\n",
    "In HDFS, a **block** is the smallest unit of data that the file system can store or process.  \n",
    "Instead of storing a massive 10 GB file as one giant piece, HDFS chops it into smaller, uniform chunks.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Use Blocks?\n",
    "\n",
    "- **Parallel Processing:**  \n",
    "  Since a file is split into many blocks, different servers (DataNodes) can process different parts of the same file simultaneously, drastically speeding up big data tasks.\n",
    "\n",
    "- **Fault Tolerance:**  \n",
    "  Each block is copied (replicated) to multiple servers (usually 3). If one server crashes, the system retrieves a copy of the block from another server.\n",
    "\n",
    "- **Scalability:**  \n",
    "  A single file can be larger than any individual hard drive in the cluster because its blocks can be distributed across hundreds of different disk\n",
    "\n",
    "\n",
    "### Components\n",
    "- **NameNode:**  \n",
    "  The master node that manages the file system namespace, maintains the file system tree, and tracks metadata for files.  \n",
    "\n",
    "  ## **NameNode Function FsImage, EditLog and Other HDFS Metadata Files (Explained Simply)**\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### FsImage\n",
    "\n",
    "  FsImage is a snapshot of the HDFS file system metadata at a point in time.\n",
    "\n",
    "  It contains:\n",
    "  - Directory structure  \n",
    "  - File names  \n",
    "  - Permissions  \n",
    "  - Block mappings (file ‚Üí block IDs)  \n",
    "\n",
    "  üìå **FsImage does NOT store actual data ‚Äî only metadata.**\n",
    "\n",
    "  Think of it as:  \n",
    "  > A photograph of the HDFS namespace.\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### EditLog\n",
    "\n",
    "  EditLog records every change made to HDFS after the FsImage was created.\n",
    "\n",
    "  Examples:\n",
    "  - Create file  \n",
    "  - Delete file  \n",
    "  - Rename file  \n",
    "  - Change permissions  \n",
    "\n",
    "  Why it exists:\n",
    "  - Writing to FsImage every time would be slow  \n",
    "  - EditLog lets NameNode log changes efficiently  \n",
    "\n",
    "  Think of it as:  \n",
    "  > A transaction log.\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### How FsImage + EditLog Work Together\n",
    "\n",
    "  - NameNode loads FsImage  \n",
    "  - Replays EditLog on top of it  \n",
    "  - Reconstructs the latest HDFS state in memory  \n",
    "\n",
    "  Without EditLog ‚Üí **data loss**  \n",
    "  Without FsImage ‚Üí **slow startup**\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### Secondary NameNode (Important!)\n",
    "\n",
    "  Despite the name, it is **NOT** a backup NameNode.\n",
    "\n",
    "  What it does:\n",
    "  - Periodically fetches FsImage and EditLog  \n",
    "  - Merges them into a new FsImage  \n",
    "  - Sends the compacted FsImage back  \n",
    "\n",
    "  Purpose:\n",
    "  - Prevents EditLog from growing too large  \n",
    "  - Reduces NameNode restart time  \n",
    "\n",
    "  ---\n",
    "\n",
    "  ### Checkpoint Node / Standby NameNode\n",
    "\n",
    "  In modern Hadoop:\n",
    "  - Checkpoint Node or Standby NameNode replaces Secondary NameNode  \n",
    "  - Provides high availability  \n",
    "  - Keeps metadata in sync using ZooKeeper  \n",
    "\n",
    "  ---\n",
    "\n",
    "  ### Interview-Ready Summary\n",
    "\n",
    "  - **FsImage:** Snapshot of HDFS metadata  \n",
    "  - **EditLog:** Record of metadata changes  \n",
    "  - **Secondary NameNode:** Merges FsImage and EditLog  \n",
    "  - **Standby NameNode:** High availability and failover  \n",
    "\n",
    "  ---\n",
    "  ### Heartbeats and Block Reports in HDFS\n",
    "\n",
    "  The NameNode regularly receives **heartbeats** and **block reports** from all DataNodes to ensure they are alive and to maintain accurate metadata about block locations.\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### Heartbeat\n",
    "  - Sent frequently (every ~3 seconds by default)  \n",
    "  - Tells the NameNode:  \n",
    "    > ‚ÄúI am alive and functioning‚Äù  \n",
    "  - If heartbeats stop for a threshold time, the DataNode is marked **dead**\n",
    "\n",
    "  ---\n",
    "\n",
    "  ### Block Report\n",
    "  - Sent less frequently (about once per hour by default)  \n",
    "  - Contains:  \n",
    "    - List of all blocks stored on that DataNode  \n",
    "  - Used by the NameNode to:  \n",
    "    - Track block locations  \n",
    "    - Detect under-replicated or over-replicated blocks  \n",
    "  ---\n",
    "\n",
    "- **DataNodes:**  \n",
    "  Slave nodes that store actual data blocks and perform block creation, deletion, and replication upon instructions from the NameNode.\n",
    "\n",
    "  ## **DataNode Functions and HDFS Read/Write Process**\n",
    "\n",
    "  ### Main Functions of DataNode\n",
    "  - **Store Blocks:** Stores actual data blocks on local disks.  \n",
    "  - **Serve Client Requests:** Reads and writes blocks for clients.  \n",
    "  - **Heartbeat:** Sends regular heartbeats to the NameNode to indicate it is alive.  \n",
    "  - **Block Report:** Periodically sends a list of all stored blocks to the NameNode.  \n",
    "  - **Block Replication:** Replicates blocks to other DataNodes when instructed by the NameNode.  \n",
    "  - **Block Deletion:** Deletes blocks when files are removed or over-replicated.  \n",
    "  - **Data Integrity:** Maintains checksums for blocks to detect corruption.  \n",
    "\n",
    "  ### **HDFS Write Process (Client ‚Üí HDFS)**\n",
    "  1. Client contacts the **NameNode** for block allocation.  \n",
    "  2. NameNode returns a list of **DataNodes** where each block will be stored (default 3 replicas).  \n",
    "  3. Client splits the file into blocks and sends each block to the **first DataNode**.  \n",
    "  4. The first DataNode writes the block and pipelines it to the **second DataNode**, which then pipelines to the **third DataNode**.  \n",
    "  5. Each DataNode sends an **acknowledgement** back along the pipeline to the client.  \n",
    "  6. Once all blocks are written and acknowledged, the write is complete.\n",
    "\n",
    "  **Write Pipeline Diagram:**<br>\n",
    "\n",
    "  ![image-8.png](attachment:image-8.png)\n",
    "\n",
    "  **Explanation:**\n",
    "\n",
    "  - Client asks NameNode for block locations.\n",
    "  - NameNode chooses three DataNodes (DN1, DN2, DN3).\n",
    "  - Client sends block to DN1 ‚Üí pipelined to DN2 ‚Üí pipelined to DN3.\n",
    "  - Each DataNode sends acknowledgment back to client.\n",
    "  \n",
    "  ---\n",
    "\n",
    "  ### **HDFS Read Process (Client ‚Üê HDFS)**\n",
    "  1. Client contacts **NameNode** to get the block locations for the file.  \n",
    "  2. NameNode returns the list of DataNodes storing each block.  \n",
    "  3. Client reads blocks **directly from the nearest DataNode** to optimize network usage.  \n",
    "  4. If a DataNode is down, the client automatically reads the block from the next replica.\n",
    "\n",
    "  **Read diagram (text-based):**<br>\n",
    "\n",
    "  ![image-9.png](attachment:image-9.png)\n",
    "  \n",
    "  **Explanation:**\n",
    "\n",
    "  - Client asks NameNode where the blocks are.\n",
    "  - NameNode returns DataNode locations.\n",
    "  - Client reads blocks from the closest or fastest replica.\n",
    "\n",
    "\n",
    "### Key Features\n",
    "- **Fault Tolerance:** Automatic recovery from node failures through data replication  \n",
    "- **High Throughput:** Designed for streaming data access rather than low-latency random access  \n",
    "- **Scalability:** Can be scaled to thousands of nodes, holding petabytes of data  \n",
    "\n",
    "### Commands\n",
    "- Similar to Linux commands, using `hdfs dfs` or `hadoop fs` for file management (e.g., `ls`, `put`, `get`)\n",
    "\n",
    "\n",
    "## 1Ô∏è‚É£ What is MapReduce?\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Apache Hadoop MapReduce is the original distributed processing model designed to process huge datasets by breaking work into two rigid phases:\n",
    "- Map ‚Äì process input data\n",
    "- Reduce ‚Äì aggregate results\n",
    "\n",
    "**How it works**<br>\n",
    "Input ‚Üí Map ‚Üí Disk ‚Üí Shuffle ‚Üí Disk ‚Üí Reduce ‚Üí Output<br>\n",
    "\n",
    "‚ö†Ô∏è *Every step writes to disk*\n",
    "\n",
    "## Execution Model\n",
    "\n",
    "**MapReduce (Rigid & Linear)**\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n",
    "- Only 2 stages\n",
    "- No optimization across stages\n",
    "- Intermediate results ‚Üí disk ‚Üí network ‚Üí disk\n",
    "\n",
    "## Programming Experience\n",
    "\n",
    "**MapReduce (Java-heavy üòì)**\n",
    "```JAVA\n",
    "public class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\n",
    "    public void map(LongWritable key, Text value, Context context) {\n",
    "        // boilerplate-heavy\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "## 2Ô∏è‚É£ What is Apache Spark?\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Apache Spark is a general-purpose distributed computing engine designed for speed, flexibility, and advanced analytics.\n",
    "\n",
    "**How it works**<br>\n",
    "Input ‚Üí In-Memory Processing ‚Üí DAG Execution ‚Üí Output<br>\n",
    "\n",
    "üî• *Data stays in memory whenever possible*\n",
    "\n",
    "## Execution Model\n",
    "\n",
    "**Spark (Flexible DAG)**\n",
    "\n",
    "![image-5.png](attachment:image-5.png)\n",
    "![image-6.png](attachment:image-6.png)\n",
    "\n",
    "- Directed Acyclic Graph (DAG)\n",
    "- Optimizes entire job before execution\n",
    "- Keeps data in memory\n",
    "\n",
    "## Programming Experience\n",
    "\n",
    "**Spark (Python-friendly üòç)**\n",
    "```Python\n",
    "df.groupBy(\"word\").count()\n",
    "```\n",
    "\n",
    "### 3Ô∏è‚É£ Core Difference (At a Glance)\n",
    "\n",
    "| Aspect            | MapReduce        | Spark                          |\n",
    "|-------------------|------------------|--------------------------------|\n",
    "| Processing Model  | Map ‚Üí Reduce only| DAG (multiple stages)          |\n",
    "| Data Handling     | Disk-based       | In-memory                      |\n",
    "| Speed             | Slow             | ‚ö° 10‚Äì100√ó faster               |\n",
    "| Iterative Jobs    | Very inefficient | Highly efficient               |\n",
    "| Code Complexity   | High             | Simple & expressive            |\n",
    "| APIs              | Java-heavy       | SQL, Python, Scala, R          |\n",
    "| Use Cases         | Batch only       | Batch + Streaming + ML         |\n",
    "\n",
    "\n",
    "## 4Ô∏è‚É£ Performance Comparison\n",
    "| Scenario                | Winner     | Why                     |\n",
    "|-------------------------|------------|--------------------------|\n",
    "| Simple batch job        | Spark      | Less disk I/O            |\n",
    "| Iterative algorithms    | Spark      | In-memory reuse          |\n",
    "| Machine Learning        | Spark      | Native MLlib             |\n",
    "| Streaming               | Spark      | Structured Streaming     |\n",
    "| Legacy Hadoop cluster   | MapReduce  | Already exists           |\n",
    "\n",
    "\n",
    "### 5Ô∏è‚É£ Fault Tolerance (Different Philosophy)\n",
    "\n",
    "**MapReduce**  \n",
    "- Relies on disk replication (HDFS)  \n",
    "- Restarts failed tasks from disk  \n",
    "\n",
    "**Spark**  \n",
    "- Uses RDD lineage  \n",
    "- Recomputes lost partitions instead of disk reads  \n",
    "\n",
    "üëâ *Spark is smarter, MapReduce is simpler*\n",
    "\n",
    "---\n",
    "\n",
    "### 6Ô∏è‚É£ Ecosystem Support\n",
    "\n",
    "**MapReduce**  \n",
    "- Pig  \n",
    "- Hive (originally MapReduce-based)  \n",
    "\n",
    "**Spark**  \n",
    "- Spark SQL  \n",
    "- Spark Streaming  \n",
    "- MLlib  \n",
    "- GraphX  \n",
    "- Delta Lake (Databricks)  \n",
    "\n",
    "üìâ *That‚Äôs why MapReduce usage has drastically declined*\n",
    "\n",
    "---\n",
    "\n",
    "### 7Ô∏è‚É£ When Would You Still Use MapReduce?\n",
    "\n",
    "Rare, but possible:  \n",
    "- Legacy Hadoop pipelines  \n",
    "- Extremely simple batch jobs  \n",
    "- Disk-heavy compliance workflows  \n",
    "- Very limited memory environments  \n",
    "\n",
    "üëâ *New projects? Almost never.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c5e0650-3506-4da1-8e44-3ee1266d3130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üì¶ MapReduce ‚Äî Complete Detailed Guide\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ What is MapReduce?\n",
    "\n",
    "**MapReduce** is a distributed programming model and processing framework used within the Apache Hadoop ecosystem to process vast amounts of data in parallel across large clusters of commodity hardware.<p>It achieves high scalability and fault tolerance by breaking down large datasets into smaller chunks and processing them in two main phases: Map and Reduce. \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "### Core Idea\n",
    "\n",
    "> Break a large dataset into smaller chunks, process them in parallel, and combine the results.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Why MapReduce Was Needed\n",
    "\n",
    "### Before MapReduce\n",
    "\n",
    "* Single machine processing\n",
    "* Limited CPU, memory, and storage\n",
    "* No fault tolerance\n",
    "* Scaling required expensive hardware upgrades\n",
    "\n",
    "### With MapReduce\n",
    "\n",
    "* Data split across multiple machines\n",
    "* Parallel execution\n",
    "* Automatic fault tolerance\n",
    "* Horizontal scalability\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ High-Level Architecture\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Main Components:\n",
    "\n",
    "| Component                    | Description                                          |\n",
    "| ---------------------------- | ---------------------------------------------------- |\n",
    "| HDFS                         | Distributed file system storing data in blocks       |\n",
    "| Mapper                       | Processes input splits and generates key-value pairs |\n",
    "| Reducer                      | Aggregates mapped output                             |\n",
    "| YARN                         | Resource management layer                            |\n",
    "| ResourceManager / JobTracker | Coordinates job execution                            |\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ End-to-End Processing Flow\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "```\n",
    "Input Data\n",
    "   ‚Üì\n",
    "Input Split\n",
    "   ‚Üì\n",
    "Mapper\n",
    "   ‚Üì\n",
    "Shuffle & Sort\n",
    "   ‚Üì\n",
    "Reducer\n",
    "   ‚Üì\n",
    "Final Output\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Step 1: Input Data & Splitting\n",
    "\n",
    "* Data stored in HDFS\n",
    "* Files split into blocks (default 128 MB)\n",
    "* Each block processed by one Map task\n",
    "\n",
    "> Note: A split is a logical division, while a block is physical storage in HDFS.\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Step 2: Mapper Phase\n",
    "\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n",
    "The Mapper:\n",
    "\n",
    "* Reads input split\n",
    "* Converts raw data into key-value pairs\n",
    "* Runs independently and in parallel\n",
    "\n",
    "### Example: Word Count\n",
    "\n",
    "#### Input\n",
    "\n",
    "```\n",
    "Big data is powerful\n",
    "Big data is scalable\n",
    "```\n",
    "\n",
    "#### Mapper Output\n",
    "\n",
    "```\n",
    "(Big, 1)\n",
    "(data, 1)\n",
    "(is, 1)\n",
    "(powerful, 1)\n",
    "(Big, 1)\n",
    "(data, 1)\n",
    "(is, 1)\n",
    "(scalable, 1)\n",
    "```\n",
    "\n",
    "Characteristics:\n",
    "\n",
    "* Stateless\n",
    "* Parallel execution\n",
    "* No communication between mappers\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Step 3: Shuffle & Sort (Core Phase)\n",
    "\n",
    "![image-5.png](attachment:image-5.png)\n",
    "\n",
    "This phase:\n",
    "\n",
    "1. Writes mapper output to local disk\n",
    "2. Groups records by key\n",
    "3. Transfers grouped keys to appropriate reducers\n",
    "4. Sorts keys\n",
    "\n",
    "### Example After Shuffle\n",
    "\n",
    "```\n",
    "Big ‚Üí [1, 1]\n",
    "data ‚Üí [1, 1]\n",
    "is ‚Üí [1, 1]\n",
    "powerful ‚Üí [1]\n",
    "scalable ‚Üí [1]\n",
    "```\n",
    "\n",
    "This stage involves heavy:\n",
    "\n",
    "* Disk I/O\n",
    "* Network transfer\n",
    "* Sorting overhead\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ Step 4: Reducer Phase\n",
    "\n",
    "![image-6.png](attachment:image-6.png)\n",
    "\n",
    "Reducer:\n",
    "\n",
    "* Takes key + list of values\n",
    "* Performs aggregation\n",
    "* Writes final output to HDFS\n",
    "\n",
    "### Example Output\n",
    "\n",
    "```\n",
    "(Big, [1,1]) ‚Üí (Big, 2)\n",
    "(data, [1,1]) ‚Üí (data, 2)\n",
    "(is, [1,1]) ‚Üí (is, 2)\n",
    "(powerful, [1]) ‚Üí (powerful, 1)\n",
    "(scalable, [1]) ‚Üí (scalable, 1)\n",
    "```\n",
    "\n",
    "![image-7.png](attachment:image-7.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ Disk-Based Nature\n",
    "\n",
    "MapReduce writes to disk multiple times:\n",
    "\n",
    "**Disk writes happen at:**\n",
    "\n",
    "- Mapper output\n",
    "- Shuffle phase\n",
    "- Reducer output\n",
    "\n",
    "```\n",
    "Map ‚Üí Disk ‚Üí Network ‚Üí Disk ‚Üí Reduce ‚Üí Disk\n",
    "```\n",
    "\n",
    "This ensures reliability but reduces performance.\n",
    "\n",
    "---\n",
    "\n",
    "## üîü Fault Tolerance\n",
    "\n",
    "MapReduce handles failures by:\n",
    "\n",
    "* Re-executing failed tasks on other nodes\n",
    "* Using HDFS replication for data safety\n",
    "* Master node tracking task status\n",
    "\n",
    "Reliable but slower recovery compared to modern systems.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£1Ô∏è‚É£ Programming Model (Why Devs Hated It üòÖ)\n",
    "\n",
    "Characteristics:\n",
    "\n",
    "* Mostly Java-based\n",
    "* High boilerplate code\n",
    "* Rigid two-stage model (Map ‚Üí Reduce)\n",
    "* Not suitable for iterative processing\n",
    "\n",
    "### Pseudocode Structure\n",
    "\n",
    "```\n",
    "map(key, value):\n",
    "    emit(intermediate_key, intermediate_value)\n",
    "\n",
    "reduce(key, list_of_values):\n",
    "    aggregate values\n",
    "    emit(final_key, final_value)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£2Ô∏è‚É£ Strengths\n",
    "\n",
    "* Handles massive datasets\n",
    "* Strong fault tolerance\n",
    "* Deterministic batch jobs\n",
    "* Works on commodity hardware\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£3Ô∏è‚É£ Limitations\n",
    "\n",
    "* Heavy disk dependency\n",
    "* Slow for iterative algorithms\n",
    "* Complex development\n",
    "* Batch processing only\n",
    "* No native streaming support\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£4Ô∏è‚É£ When to Use MapReduce\n",
    "\n",
    "Use when:\n",
    "\n",
    "* Legacy Hadoop cluster exists\n",
    "* Large batch jobs required\n",
    "* Memory resources are limited\n",
    "\n",
    "Avoid for:\n",
    "\n",
    "* Real-time analytics\n",
    "* Machine learning workloads\n",
    "* Streaming systems\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£5Ô∏è‚É£ Conceptual Summary\n",
    "\n",
    "| Feature          | MapReduce              |\n",
    "| ---------------- | ---------------------- |\n",
    "| Processing Model | Map ‚Üí Shuffle ‚Üí Reduce |\n",
    "| Storage          | Disk-based             |\n",
    "| Speed            | Slower                 |\n",
    "| Scalability      | Horizontal             |\n",
    "| Fault Tolerance  | High                   |\n",
    "| Use Case         | Batch processing       |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Final Understanding\n",
    "\n",
    "MapReduce is the foundation of distributed batch processing.\n",
    "\n",
    "It introduced:\n",
    "\n",
    "* Parallel data processing\n",
    "* Data locality\n",
    "* Automatic fault tolerance\n",
    "* Horizontal scaling\n",
    "\n",
    "While modern systems (like Spark) improved performance by using in-memory processing and DAG execution, the core distributed computing principles originated from MapReduce.\n",
    "\n",
    "---\n",
    "\n",
    "# End of Document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40fd3791-b0cd-4c9a-8840-e997d01a559f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üèó Hadoop MapReduce Internal Architecture ‚Äî Deep Conceptual Guide\n",
    "\n",
    "MapReduce runs inside the Hadoop ecosystem. Over time, Hadoop evolved from **Hadoop 1.x (JobTracker model)** to **Hadoop 2.x+ (YARN architecture)** to improve scalability, flexibility, and fault tolerance.\n",
    "\n",
    "There are two major architectures:\n",
    "\n",
    "* **Hadoop 1.x** ‚Üí JobTracker & TaskTracker\n",
    "* **Hadoop 2.x+** ‚Üí YARN (ResourceManager & NodeManager)\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Big Picture ‚Äî Layered Architecture\n",
    "\n",
    "```\n",
    "+--------------------------------------------------+\n",
    "|                Hadoop Ecosystem                  |\n",
    "+--------------------------------------------------+\n",
    "|                                                  |\n",
    "|   +-------------------+     +-----------------+  |\n",
    "|   |       HDFS        |     |      YARN       |  |\n",
    "|   | (Storage Layer)   |     | (Cluster Mgmt)  |  |\n",
    "|   +-------------------+     +-----------------+  |\n",
    "|                                      |            |\n",
    "|                         -------------------------  |\n",
    "|                         |          |           |   |\n",
    "|                   ResourceManager NodeManager  AM  |\n",
    "|                                                  |\n",
    "+--------------------------------------------------+\n",
    "```\n",
    "\n",
    "## üîπ Important Understanding\n",
    "\n",
    "* **HDFS** ‚Üí Storage Layer\n",
    "* **YARN** ‚Üí Resource Management Layer\n",
    "* **MapReduce / Spark / Tez** ‚Üí Applications running on YARN\n",
    "\n",
    "üëâ ResourceManager and NodeManager belong to **YARN**, not directly to MapReduce.\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ Hadoop 1.x Architecture (Classic MapReduce)\n",
    "\n",
    "In Hadoop 1.x, resource management and job execution were tightly coupled.\n",
    "\n",
    "## üèó Architecture Diagram ‚Äî Hadoop 1.x\n",
    "\n",
    "```\n",
    "                    +-------------------+\n",
    "                    |     Client        |\n",
    "                    +---------+---------+\n",
    "                              |\n",
    "                              v\n",
    "                    +-------------------+\n",
    "                    |    JobTracker     |\n",
    "                    |   (Master Node)   |\n",
    "                    +---------+---------+\n",
    "                              |\n",
    "        -----------------------------------------------\n",
    "        |                     |                       |\n",
    "        v                     v                       v\n",
    "+---------------+     +---------------+       +---------------+\n",
    "| TaskTracker 1 |     | TaskTracker 2 |  ...  | TaskTracker N |\n",
    "| (Worker Node) |     | (Worker Node) |       | (Worker Node) |\n",
    "+-------+-------+     +-------+-------+       +-------+-------+\n",
    "        |                     |                       |\n",
    "        v                     v                       v\n",
    "   Map / Reduce          Map / Reduce           Map / Reduce\n",
    "      Tasks                 Tasks                  Tasks\n",
    "\n",
    "(All nodes read/write data from HDFS)\n",
    "```\n",
    "\n",
    "## üîπ JobTracker (Master Node)\n",
    "\n",
    "The **JobTracker** was the central authority of the cluster.\n",
    "\n",
    "### Responsibilities\n",
    "\n",
    "* Accept MapReduce jobs from clients\n",
    "* Divide jobs into Map and Reduce tasks\n",
    "* Schedule tasks on TaskTrackers\n",
    "* Monitor task progress\n",
    "* Restart failed tasks\n",
    "* Maintain job metadata\n",
    "\n",
    "### Characteristics\n",
    "\n",
    "* Single point of failure ‚ùå\n",
    "* High memory load\n",
    "* Limited scalability\n",
    "\n",
    "If the JobTracker crashed ‚Üí the entire cluster stopped.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ TaskTracker (Worker Node)\n",
    "\n",
    "Each worker machine ran a **TaskTracker**.\n",
    "\n",
    "### Responsibilities\n",
    "\n",
    "* Execute Map tasks\n",
    "* Execute Reduce tasks\n",
    "* Send heartbeats to JobTracker\n",
    "* Report task progress\n",
    "\n",
    "### Slot-Based Execution Model\n",
    "\n",
    "Each TaskTracker had fixed:\n",
    "\n",
    "* Map slots\n",
    "* Reduce slots\n",
    "\n",
    "This caused inefficient resource utilization because CPU and memory were not dynamically allocated.\n",
    "\n",
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ Hadoop 2.x+ Architecture (YARN ‚Äî Yet Another Resource Negotiator)\n",
    "\n",
    "To overcome Hadoop 1.x limitations, **YARN** was introduced.\n",
    "\n",
    "## üèó Architecture Diagram ‚Äî Hadoop 2.x (YARN)\n",
    "\n",
    "```\n",
    "                     +-------------------+\n",
    "                     |      Client       |\n",
    "                     +---------+---------+\n",
    "                               |\n",
    "                               v\n",
    "                     +-------------------+\n",
    "                     |  ResourceManager  |\n",
    "                     |   (Cluster Master)|\n",
    "                     +---------+---------+\n",
    "                               |\n",
    "                ---------------------------------\n",
    "                |                               |\n",
    "                v                               v\n",
    "     +-------------------+           +-------------------+\n",
    "     | ApplicationMaster |           |  NodeManager 1    |\n",
    "     |  (Per Application)|           |  (Worker Node)    |\n",
    "     +---------+---------+           +---------+---------+\n",
    "               |                               |\n",
    "               |                               v\n",
    "               |                        +---------------+\n",
    "               |                        |  Containers   |\n",
    "               |                        | (Map/Reduce)  |\n",
    "               |                        +---------------+\n",
    "               |\n",
    "               v\n",
    "     +-------------------+\n",
    "     |  NodeManager N    |\n",
    "     +---------+---------+\n",
    "               |\n",
    "               v\n",
    "        +---------------+\n",
    "        |  Containers   |\n",
    "        +---------------+\n",
    "\n",
    "(All containers read/write data from HDFS)\n",
    "```\n",
    "---\n",
    "\n",
    "YARN separates:\n",
    "\n",
    "* Resource management\n",
    "* Job scheduling and execution\n",
    "\n",
    "---\n",
    "\n",
    "# üîπ Where Do ResourceManager & NodeManager Belong?\n",
    "\n",
    "They belong under:\n",
    "\n",
    "# ‚úÖ YARN (Resource Management Layer)\n",
    "\n",
    "Hierarchy:\n",
    "\n",
    "```\n",
    "Hadoop\n",
    "   ‚îú‚îÄ‚îÄ HDFS\n",
    "   ‚îî‚îÄ‚îÄ YARN\n",
    "         ‚îú‚îÄ‚îÄ ResourceManager\n",
    "         ‚îÇ      ‚îî‚îÄ‚îÄ Scheduler\n",
    "         ‚îú‚îÄ‚îÄ NodeManager\n",
    "         ‚îú‚îÄ‚îÄ ApplicationMaster\n",
    "         ‚îî‚îÄ‚îÄ Containers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ ResourceManager (Cluster-Level Master)\n",
    "\n",
    "The **ResourceManager (RM)** manages cluster-wide resources.\n",
    "\n",
    "### Responsibilities\n",
    "\n",
    "* Allocate CPU and memory resources\n",
    "* Schedule applications\n",
    "* Enforce scheduling policies (FIFO, Capacity, Fair Scheduler)\n",
    "\n",
    "It does NOT execute tasks directly.\n",
    "\n",
    "### Internal Components\n",
    "\n",
    "1. **Scheduler** ‚Äî Allocates containers based on policies\n",
    "2. **ApplicationsManager** ‚Äî Manages application lifecycle\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ NodeManager (Worker-Level Agent)\n",
    "\n",
    "Each worker machine runs a **NodeManager (NM)**.\n",
    "\n",
    "### Responsibilities\n",
    "\n",
    "* Launch containers\n",
    "* Monitor resource usage\n",
    "* Report health to ResourceManager\n",
    "* Manage logs\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ ApplicationMaster (Per-Application Controller)\n",
    "\n",
    "For every submitted job, YARN launches a dedicated **ApplicationMaster (AM)**.\n",
    "\n",
    "### Responsibilities\n",
    "\n",
    "* Negotiate resources with ResourceManager\n",
    "* Request containers for tasks\n",
    "* Coordinate execution of Map and Reduce tasks\n",
    "* Handle task failures\n",
    "* Monitor job progress\n",
    "\n",
    "This removes the single point of failure issue present in Hadoop 1.x.\n",
    "\n",
    "---\n",
    "\n",
    "# üì¶ Container Concept (Very Important)\n",
    "\n",
    "In YARN, resources are allocated as **containers**.\n",
    "\n",
    "A container is:\n",
    "\n",
    "* A bundle of CPU + Memory\n",
    "* Dynamically allocated\n",
    "* Used to run tasks\n",
    "\n",
    "Unlike fixed slots in Hadoop 1.x, containers allow better cluster utilization and flexibility.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Conceptual Execution Flow in YARN\n",
    "\n",
    "```\n",
    "1. Client submits job\n",
    "2. ResourceManager allocates container for ApplicationMaster\n",
    "3. ApplicationMaster starts\n",
    "4. ApplicationMaster requests containers for tasks\n",
    "5. NodeManagers execute Map & Reduce tasks inside containers\n",
    "6. Tasks report progress back to ApplicationMaster\n",
    "7. Final output written to HDFS\n",
    "```\n",
    "\n",
    "![image-2.png](attachment:image-2.png) <p>\n",
    "\n",
    "## ** üèó Simple YARN Architecture Diagram**\n",
    "\n",
    "```\n",
    "                    +------------------+\n",
    "                    |      Client      |\n",
    "                    +--------+---------+\n",
    "                             |\n",
    "                             v\n",
    "                    +------------------+\n",
    "                    | ResourceManager  |\n",
    "                    |   (Cluster Boss) |\n",
    "                    +--------+---------+\n",
    "                             |\n",
    "              ---------------------------------\n",
    "              |                               |\n",
    "              v                               v\n",
    "     +----------------+              +----------------+\n",
    "     | NodeManager 1  |              | NodeManager 2  |\n",
    "     | (Worker Node)  |              | (Worker Node)  |\n",
    "     +--------+-------+              +--------+-------+\n",
    "              |                               |\n",
    "              |                               |\n",
    "      +-------+-------+               +-------+-------+\n",
    "      |  Container    |               |  Container    |\n",
    "      | (Task Runs)   |               | (Task Runs)   |\n",
    "      +-------+-------+               +-------+-------+\n",
    "              |                               |\n",
    "              |                               |\n",
    "        +-------------+                +-------------+\n",
    "        | Map Task    |                | Reduce Task |\n",
    "        +-------------+                +-------------+\n",
    "\n",
    "        (ApplicationMaster runs inside one container)\n",
    "\n",
    "```\n",
    "**üëâ ApplicationMaster should logically appear above NodeManagers in the control flow.**\n",
    "\n",
    "But‚Ä¶\n",
    "\n",
    "**üëâ Physically, it actually runs inside a container on one of the NodeManagers.**\n",
    "\n",
    "\n",
    "**Because:**\n",
    "\n",
    "- ApplicationMaster is launched inside a container\n",
    "- That container runs on a NodeManager\n",
    "\n",
    "\n",
    "## Physical Deployment View (Where It Actually Runs)\n",
    "\n",
    "```\n",
    "NodeManager 1\n",
    "   ‚îú‚îÄ‚îÄ Container (ApplicationMaster)\n",
    "   ‚îú‚îÄ‚îÄ Container (Map Task)\n",
    "\n",
    "NodeManager 2\n",
    "   ‚îú‚îÄ‚îÄ Container (Reduce Task)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üìä Hadoop 1.x vs Hadoop 2.x Comparison\n",
    "\n",
    "| Feature                 | Hadoop 1.x   | Hadoop 2.x (YARN) |\n",
    "| ----------------------- | ------------ | ----------------- |\n",
    "| Master Component        | JobTracker   | ResourceManager   |\n",
    "| Worker Component        | TaskTracker  | NodeManager       |\n",
    "| Job-Level Manager       | Not Separate | ApplicationMaster |\n",
    "| Resource Allocation     | Slot-based   | Container-based   |\n",
    "| Scalability             | Limited      | High              |\n",
    "| Single Point of Failure | Yes          | No                |\n",
    "| Flexibility             | Low          | High              |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Final Internal Architecture Understanding\n",
    "\n",
    "Hadoop MapReduce evolved from a tightly coupled architecture (JobTracker/TaskTracker) to a flexible and scalable model (YARN).\n",
    "\n",
    "**Hadoop 1.x**\n",
    "\n",
    "* Centralized control\n",
    "* Limited scalability\n",
    "* Single failure risk\n",
    "\n",
    "**Hadoop 2.x (YARN)**\n",
    "\n",
    "* Decoupled resource management\n",
    "* Better fault tolerance\n",
    "* Improved scalability\n",
    "* Efficient resource utilization\n",
    "\n",
    "This architectural evolution made Hadoop enterprise-ready and capable of supporting not just MapReduce but also Spark, Tez, and other distributed processing engines.\n",
    "\n",
    "---\n",
    "\n",
    "# End of Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "305bbe0d-0959-4452-ab3d-fc4b4c489b57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üî• Advanced Hadoop Edge Cases ‚Äî Production-Level Understanding\n",
    "\n",
    "This document covers advanced failure scenarios and real-world behaviors in Hadoop (HDFS + YARN + MapReduce).\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ What Happens If ResourceManager Crashes?\n",
    "\n",
    "## Hadoop 1.x\n",
    "\n",
    "* JobTracker crash = Entire cluster down ‚ùå\n",
    "* Single point of failure\n",
    "\n",
    "## Hadoop 2.x (YARN)\n",
    "\n",
    "High Availability (HA) can be configured:\n",
    "\n",
    "```\n",
    "Active ResourceManager\n",
    "Standby ResourceManager\n",
    "```\n",
    "\n",
    "If Active crashes:\n",
    "\n",
    "* Standby becomes Active\n",
    "* Scheduling continues\n",
    "\n",
    "‚ö† Without HA ‚Üí No new jobs can be scheduled.\n",
    "\n",
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ What Happens If ApplicationMaster Crashes?\n",
    "\n",
    "ApplicationMaster (AM) is a **per-job controller** in YARN.\n",
    "\n",
    "If AM crashes:\n",
    "\n",
    "* YARN attempts to restart it (based on retry limit)\n",
    "* The job may resume from last known state\n",
    "* If retry limit is exceeded ‚Üí The job fails\n",
    "\n",
    "### Why This Works\n",
    "\n",
    "* AM is separate from ResourceManager\n",
    "* Failure is isolated per application\n",
    "* Other running jobs are not affected\n",
    "\n",
    "---\n",
    "\n",
    "# ‚öô How to Configure ApplicationMaster Retry Limit\n",
    "\n",
    "YARN allows configuring how many times an ApplicationMaster can be retried before marking the job as failed.\n",
    "\n",
    "## üîß Configuration Property\n",
    "\n",
    "In `yarn-site.xml`:\n",
    "\n",
    "```\n",
    "yarn.resourcemanager.am.max-attempts\n",
    "```\n",
    "\n",
    "### Example Configuration\n",
    "\n",
    "```\n",
    "<property>\n",
    "  <name>yarn.resourcemanager.am.max-attempts</name>\n",
    "  <value>4</value>\n",
    "</property>\n",
    "```\n",
    "\n",
    "This means:\n",
    "\n",
    "* YARN will try to restart the ApplicationMaster up to **4 times**\n",
    "* If it crashes more than 4 times ‚Üí Job fails\n",
    "\n",
    "---\n",
    "\n",
    "# üìå Job-Level Override (Optional)\n",
    "\n",
    "You can also configure max attempts per job:\n",
    "\n",
    "For MapReduce jobs:\n",
    "\n",
    "```\n",
    "mapreduce.am.max-attempts\n",
    "```\n",
    "\n",
    "Example in `mapred-site.xml`:\n",
    "\n",
    "```\n",
    "<property>\n",
    "  <name>mapreduce.am.max-attempts</name>\n",
    "  <value>3</value>\n",
    "</property>\n",
    "```\n",
    "\n",
    "This overrides cluster-level setting for MapReduce applications.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† How Restart Works Internally\n",
    "\n",
    "1. ApplicationMaster container crashes\n",
    "2. ResourceManager detects failure\n",
    "3. ResourceManager allocates a new container\n",
    "4. New ApplicationMaster instance starts\n",
    "5. Job recovery logic resumes execution (if supported)\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ö† Important Production Considerations\n",
    "\n",
    "* Too many retries ‚Üí Wastes cluster resources\n",
    "* Too few retries ‚Üí Temporary issues may fail job prematurely\n",
    "* Jobs writing to external systems must handle idempotency\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Summary Table\n",
    "\n",
    "| Configuration                        | Purpose                      |\n",
    "| ------------------------------------ | ---------------------------- |\n",
    "| yarn.resourcemanager.am.max-attempts | Cluster-level AM retry limit |\n",
    "| mapreduce.am.max-attempts            | Job-level retry limit        |\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ Final Takeaway\n",
    "\n",
    "ApplicationMaster failures are isolated and recoverable.\n",
    "\n",
    "Retry behavior is configurable and should be tuned based on:\n",
    "\n",
    "* Job criticality\n",
    "* Cluster stability\n",
    "* External system dependencies\n",
    "\n",
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ What Happens If NodeManager Crashes?\n",
    "\n",
    "If a NodeManager fails:\n",
    "\n",
    "* All containers on that node stop\n",
    "* ResourceManager marks node as unhealthy\n",
    "* Tasks are rescheduled on other nodes\n",
    "\n",
    "System continues running.\n",
    "\n",
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ What Happens If Container Crashes?\n",
    "\n",
    "Container = Execution unit (CPU + Memory bundle)\n",
    "\n",
    "If container crashes:\n",
    "\n",
    "* ApplicationMaster detects failure\n",
    "* Requests a new container\n",
    "* Task re-executed\n",
    "\n",
    "Fault tolerance handled at application level.\n",
    "\n",
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ HDFS Block Corruption Scenario\n",
    "\n",
    "HDFS default replication factor = 3\n",
    "\n",
    "If one replica is corrupted:\n",
    "\n",
    "* NameNode detects corruption using checksums\n",
    "* Re-replicates from healthy replica\n",
    "* No data loss\n",
    "\n",
    "If all replicas are lost:\n",
    "\n",
    "* Data is permanently lost ‚ùå\n",
    "\n",
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ Data Locality Edge Case\n",
    "\n",
    "YARN tries to run Map tasks where data exists.\n",
    "\n",
    "Priority order:\n",
    "\n",
    "1. Node-local\n",
    "2. Rack-local\n",
    "3. Off-rack\n",
    "\n",
    "Goal:\n",
    "\n",
    "* Minimize network transfer\n",
    "* Improve performance\n",
    "\n",
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Straggler Problem (Slow Task Issue)\n",
    "\n",
    "Sometimes one task runs much slower than others.\n",
    "\n",
    "Cause:\n",
    "\n",
    "* Slow hardware\n",
    "* Disk issue\n",
    "* Network latency\n",
    "\n",
    "Solution:\n",
    "\n",
    "üëâ Speculative Execution\n",
    "\n",
    "* Hadoop launches duplicate task on another node\n",
    "* First completed task wins\n",
    "* Slower task is killed\n",
    "\n",
    "Improves overall job completion time.\n",
    "\n",
    "‚ö† Can increase cluster resource usage.\n",
    "\n",
    "# üöÄ Speculative Execution in Hadoop ‚Äî Detailed Notes\n",
    "\n",
    "Excellent clarification ‚Äî this is a very important concept in Hadoop performance tuning.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Short Answer\n",
    "\n",
    "üëâ **No, Hadoop does NOT always create duplicate tasks.**\n",
    "Speculative execution is **conditional and configurable**.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† When Does Speculative Execution Happen?\n",
    "\n",
    "Hadoop monitors:\n",
    "\n",
    "* Average task progress\n",
    "* Individual task progress\n",
    "\n",
    "If a task is:\n",
    "\n",
    "* Significantly slower than others\n",
    "* Lagging behind average completion rate\n",
    "\n",
    "Then Hadoop may:\n",
    "\n",
    "üëâ Launch a duplicate copy of that slow task on another node.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ùå It Does NOT Happen Every Time\n",
    "\n",
    "Speculative execution is triggered only when:\n",
    "\n",
    "```\n",
    "Slow Task Progress  <<  Average Task Progress\n",
    "```\n",
    "\n",
    "If all tasks are progressing normally:\n",
    "\n",
    "üëâ No duplicate tasks are created.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚öô Configuration Required?\n",
    "\n",
    "Yes ‚Äî speculative execution is configurable.\n",
    "\n",
    "By default (in many Hadoop setups):\n",
    "\n",
    "* Map speculative execution ‚Üí ENABLED\n",
    "* Reduce speculative execution ‚Üí DISABLED (sometimes)\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Important Configuration Properties\n",
    "\n",
    "In `mapred-site.xml`:\n",
    "\n",
    "```\n",
    "mapreduce.map.speculative=true\n",
    "mapreduce.reduce.speculative=true\n",
    "```\n",
    "\n",
    "You can:\n",
    "\n",
    "* Enable for Map tasks only\n",
    "* Disable for Reduce tasks\n",
    "* Disable completely\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Why Reduce Speculation Is Risky?\n",
    "\n",
    "Reduce tasks:\n",
    "\n",
    "* Pull large shuffle data\n",
    "* Consume heavy network bandwidth\n",
    "* Use significant memory\n",
    "\n",
    "Duplicate reduce tasks can overload cluster resources.\n",
    "\n",
    "üëâ Therefore, many production clusters disable reduce speculation.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† How Hadoop Decides a Task is Slow\n",
    "\n",
    "Hadoop checks:\n",
    "\n",
    "* Task progress percentage\n",
    "* Progress rate (speed of progress)\n",
    "* Comparison with cluster median\n",
    "\n",
    "If a task is:\n",
    "\n",
    "* X% slower than the median\n",
    "* Running much longer than expected\n",
    "\n",
    "It is marked as a **straggler**.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚ö† When Speculative Execution Is Dangerous\n",
    "\n",
    "Speculative execution is risky for:\n",
    "\n",
    "1Ô∏è‚É£ Non-idempotent tasks\n",
    "2Ô∏è‚É£ External system writes (DB updates, APIs)\n",
    "3Ô∏è‚É£ Financial transactions\n",
    "4Ô∏è‚É£ Streaming systems\n",
    "\n",
    "Because:\n",
    "\n",
    "üëâ Duplicate tasks may execute twice.\n",
    "\n",
    "### Example\n",
    "\n",
    "If a reduce task writes to a MySQL table ‚Üí duplicate insert risk.\n",
    "\n",
    "---\n",
    "\n",
    "# üèó Example Scenario\n",
    "\n",
    "Cluster has 10 Map tasks:\n",
    "\n",
    "* 9 tasks finish in 2 minutes\n",
    "* 1 task runs for 6 minutes\n",
    "\n",
    "Hadoop detects abnormal slowness.\n",
    "\n",
    "It launches a duplicate task on another node.\n",
    "\n",
    "Whichever finishes first:\n",
    "\n",
    "* Output is kept\n",
    "* Other task is killed\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Final Summary\n",
    "\n",
    "| Question                            | Answer                |\n",
    "| ----------------------------------- | --------------------- |\n",
    "| Does Hadoop always duplicate tasks? | ‚ùå No                  |\n",
    "| Is it automatic?                    | ‚úÖ Yes (if enabled)    |\n",
    "| Is it configurable?                 | ‚úÖ Yes                 |\n",
    "| Should it always be enabled?        | ‚ö† Depends on workload |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# 8Ô∏è‚É£ Shuffle Failure Scenario\n",
    "\n",
    "Shuffle phase involves heavy disk + network I/O.\n",
    "\n",
    "If reducer cannot fetch mapper output:\n",
    "\n",
    "* It retries\n",
    "* If repeated failure ‚Üí Mapper task re-executed\n",
    "\n",
    "Ensures data consistency.\n",
    "\n",
    "---\n",
    "\n",
    "# üß† Advanced Conceptual Questions\n",
    "\n",
    "1. Why is NameNode traditionally not distributed?\n",
    "2. Why is shuffle the most expensive phase?\n",
    "3. Why is MapReduce inefficient for iterative ML workloads?\n",
    "4. Why was YARN introduced instead of improving JobTracker?\n",
    "5. What is the difference between a container and a JVM?\n",
    "6. Why can speculative execution be dangerous in some workloads?\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Scenario-Based Thinking Exercise\n",
    "\n",
    "Scenario:\n",
    "\n",
    "* 3 NodeManagers\n",
    "* Replication factor = 3\n",
    "* One NodeManager crashes\n",
    "* One container crashes on another node\n",
    "\n",
    "Questions to Analyze:\n",
    "\n",
    "1. Is data lost?\n",
    "2. Does the job fail?\n",
    "3. Who detects the failure?\n",
    "4. Who reschedules the task?\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ Key Takeaway\n",
    "\n",
    "Hadoop is built for:\n",
    "\n",
    "* Fault tolerance\n",
    "* Horizontal scalability\n",
    "* Commodity hardware failures\n",
    "\n",
    "Failures are expected ‚Äî not exceptional.\n",
    "\n",
    "Understanding these edge cases makes your Hadoop knowledge production-ready.\n",
    "\n",
    "---\n",
    "\n",
    "# End of Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93cdefef-12b0-4c26-9d79-cbb8409eb7af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üöÄ Apache Spark Architecture ‚Äî Complete Guide for Data Engineer Interviews\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ What is Apache Spark?\n",
    "\n",
    "Apache Spark is a distributed data processing engine designed for:\n",
    "\n",
    "- Large-scale batch processing\n",
    "- Real-time streaming\n",
    "- Machine learning\n",
    "- Graph processing\n",
    "\n",
    "Key characteristics:\n",
    "\n",
    "- In-memory optimized\n",
    "- DAG-based execution engine\n",
    "- Fault tolerant\n",
    "- Much faster than Hadoop MapReduce\n",
    "\n",
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ High-Level Spark Architecture\n",
    "\n",
    "```\n",
    "                +----------------------+\n",
    "                |      Spark Driver    |\n",
    "                |  (Master Process)    |\n",
    "                +----------+-----------+\n",
    "                           |\n",
    "              ---------------------------------\n",
    "              |               |               |\n",
    "              v               v               v\n",
    "        +------------+  +------------+  +------------+\n",
    "        |  Executor  |  |  Executor  |  |  Executor  |\n",
    "        | (Worker 1) |  | (Worker 2) |  | (Worker N) |\n",
    "        +------------+  +------------+  +------------+\n",
    "              |               |               |\n",
    "              v               v               v\n",
    "          Task Threads     Task Threads     Task Threads\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ Core Components\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Driver\n",
    "\n",
    "The Driver is the brain of a Spark application.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "- Creates SparkSession / SparkContext\n",
    "- Builds Logical Plan\n",
    "- Converts logical plan to DAG\n",
    "- Schedules stages and tasks\n",
    "- Communicates with executors\n",
    "- Collects final results\n",
    "\n",
    "Important Interview Line:\n",
    "\n",
    "> Driver coordinates computation. Executors perform computation.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Executors\n",
    "\n",
    "Executors are worker processes launched for the application.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "- Execute tasks\n",
    "- Store data in memory (cache)\n",
    "- Perform shuffle operations\n",
    "- Return results to driver\n",
    "\n",
    "Important:\n",
    "\n",
    "- One executor = one JVM\n",
    "- Executors live for the lifetime of the application\n",
    "- Each executor has multiple cores\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cluster Manager\n",
    "\n",
    "Spark requires a cluster manager for resource allocation.\n",
    "\n",
    "Supported cluster managers:\n",
    "\n",
    "- Standalone\n",
    "- YARN\n",
    "- Kubernetes\n",
    "- Mesos\n",
    "\n",
    "Cluster manager allocates:\n",
    "\n",
    "- CPU cores\n",
    "- Memory\n",
    "- Executors\n",
    "\n",
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Spark Execution Flow\n",
    "\n",
    "```\n",
    "1. User writes Spark code\n",
    "2. Driver creates logical plan\n",
    "3. DAG is generated\n",
    "4. DAG split into stages\n",
    "5. Stages split into tasks\n",
    "6. Tasks assigned to executors\n",
    "7. Executors execute tasks\n",
    "8. Results returned to driver\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ DAG (Directed Acyclic Graph)\n",
    "\n",
    "Spark does NOT follow rigid Map ‚Üí Reduce model.\n",
    "\n",
    "Instead, it builds a DAG of transformations.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "df.filter(\"age > 25\") \\\n",
    "  .groupBy(\"city\") \\\n",
    "  .count()\n",
    "```\n",
    "\n",
    "Spark analyzes entire pipeline before execution.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Global optimization\n",
    "- Reduced disk I/O\n",
    "- Better execution planning\n",
    "\n",
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ Lazy Evaluation\n",
    "\n",
    "Transformations:\n",
    "\n",
    "- filter\n",
    "- map\n",
    "- select\n",
    "- join\n",
    "- groupBy\n",
    "\n",
    "Actions:\n",
    "\n",
    "- collect\n",
    "- count\n",
    "- show\n",
    "- write\n",
    "\n",
    "Execution happens only when an action is called.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "df.count()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Stage & Task Breakdown\n",
    "\n",
    "## Stage\n",
    "\n",
    "Created by shuffle boundaries.\n",
    "\n",
    "Operations that create shuffle:\n",
    "\n",
    "- groupBy\n",
    "- join\n",
    "- reduceByKey\n",
    "- repartition\n",
    "\n",
    "Each shuffle creates a new stage.\n",
    "\n",
    "---\n",
    "\n",
    "## Task\n",
    "\n",
    "Smallest unit of execution.\n",
    "\n",
    "- One task per partition\n",
    "- Runs inside executor core\n",
    "\n",
    "If there are 100 partitions ‚Üí 100 tasks.\n",
    "\n",
    "---\n",
    "\n",
    "# 8Ô∏è‚É£ Partition Concept (Very Important)\n",
    "\n",
    "Partition = logical chunk of data.\n",
    "\n",
    "- More partitions ‚Üí more parallelism\n",
    "- Too few partitions ‚Üí underutilization\n",
    "- Too many partitions ‚Üí overhead\n",
    "\n",
    "Interview Question:\n",
    "\n",
    "Q: What determines number of tasks?  \n",
    "A: Number of partitions.\n",
    "\n",
    "---\n",
    "\n",
    "# 9Ô∏è‚É£ Shuffle in Spark\n",
    "\n",
    "Shuffle happens during:\n",
    "\n",
    "- groupBy\n",
    "- join\n",
    "- repartition\n",
    "- distinct\n",
    "\n",
    "Shuffle is expensive because:\n",
    "\n",
    "- Disk I/O\n",
    "- Network transfer\n",
    "- Sorting\n",
    "\n",
    "Optimization strategies:\n",
    "\n",
    "- Prefer reduceByKey over groupByKey\n",
    "- Use broadcast join for small tables\n",
    "- Avoid unnecessary repartition\n",
    "\n",
    "---\n",
    "\n",
    "# üîü Spark Fault Tolerance\n",
    "\n",
    "Spark uses RDD Lineage instead of replication.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "rdd1 ‚Üí rdd2 ‚Üí rdd3 ‚Üí rdd4\n",
    "```\n",
    "\n",
    "If rdd3 partition is lost:\n",
    "\n",
    "- Spark recomputes it from rdd2\n",
    "\n",
    "No need to store multiple replicas like HDFS.\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£1Ô∏è‚É£ SparkContext (Very Important)\n",
    "\n",
    "## What is SparkContext?\n",
    "\n",
    "SparkContext is the entry point to Spark functionality.\n",
    "\n",
    "SparkContext is the connection or entry point between your driver program and cluster manager/ resource manager.\n",
    "\n",
    "It represents:\n",
    "\n",
    "- Connection to cluster\n",
    "- Configuration of application\n",
    "- Resource coordination\n",
    "\n",
    "In older versions:\n",
    "\n",
    "```python\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext(appName=\"MyApp\")\n",
    "```\n",
    "\n",
    "In modern Spark:\n",
    "\n",
    "SparkSession internally creates SparkContext.\n",
    "\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Responsibilities of SparkContext\n",
    "\n",
    "- Connects to cluster manager\n",
    "- Requests executors\n",
    "- Creates RDDs\n",
    "- Tracks application metadata\n",
    "- Distributes tasks\n",
    "- Manages broadcast variables\n",
    "- Manages accumulators\n",
    "\n",
    "---\n",
    "\n",
    "## SparkContext Architecture View\n",
    "\n",
    "```\n",
    "Application Code\n",
    "       ‚Üì\n",
    "SparkSession\n",
    "       ‚Üì\n",
    "SparkContext\n",
    "       ‚Üì\n",
    "Cluster Manager\n",
    "       ‚Üì\n",
    "Executors\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Important SparkContext Concepts\n",
    "\n",
    "### 1Ô∏è‚É£ Broadcast Variables\n",
    "\n",
    "Used to send large read-only data to executors efficiently.\n",
    "\n",
    "```python\n",
    "broadcast_var = sc.broadcast(large_lookup_dict)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Accumulators\n",
    "\n",
    "Used for counters across executors.\n",
    "\n",
    "```python\n",
    "counter = sc.accumulator(0)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Only One SparkContext Per JVM\n",
    "\n",
    "You cannot create multiple SparkContexts in the same application.\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£2Ô∏è‚É£ Spark on YARN\n",
    "\n",
    "```\n",
    "Client submits Spark job\n",
    "‚Üì\n",
    "YARN allocates container\n",
    "‚Üì\n",
    "Spark Driver starts\n",
    "‚Üì\n",
    "Executors launched on NodeManagers\n",
    "```\n",
    "\n",
    "Spark uses YARN for:\n",
    "\n",
    "- Resource allocation\n",
    "- Container lifecycle\n",
    "- Scheduling\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£3Ô∏è‚É£ Spark Modes\n",
    "\n",
    "## Client Mode\n",
    "\n",
    "Driver runs on client machine.\n",
    "\n",
    "## Cluster Mode\n",
    "\n",
    "Driver runs inside cluster (recommended for production).\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£4Ô∏è‚É£ RDD vs DataFrame vs Dataset\n",
    "\n",
    "| Feature | RDD | DataFrame | Dataset |\n",
    "|----------|------|------------|----------|\n",
    "| Type Safety | Yes | No | Yes |\n",
    "| Optimization | No | Catalyst | Catalyst |\n",
    "| Performance | Slower | Faster | Faster |\n",
    "| Language | All | All | Scala/Java |\n",
    "\n",
    "Recommendation:\n",
    "\n",
    "Use DataFrame for most production workloads.\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£5Ô∏è‚É£ Catalyst Optimizer\n",
    "\n",
    "Spark SQL uses:\n",
    "\n",
    "- Logical plan\n",
    "- Optimized logical plan\n",
    "- Physical plan\n",
    "\n",
    "Optimizations include:\n",
    "\n",
    "- Predicate pushdown\n",
    "- Column pruning\n",
    "- Join reordering\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£6Ô∏è‚É£ Tungsten Engine\n",
    "\n",
    "Improves:\n",
    "\n",
    "- Memory efficiency\n",
    "- CPU efficiency\n",
    "- Binary processing\n",
    "- Cache-aware computation\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Final Architecture Flow\n",
    "\n",
    "```\n",
    "Application Code\n",
    "      ‚Üì\n",
    "Driver\n",
    "      ‚Üì\n",
    "DAG Scheduler\n",
    "      ‚Üì\n",
    "Task Scheduler\n",
    "      ‚Üì\n",
    "Executors\n",
    "      ‚Üì\n",
    "Cluster Manager\n",
    "      ‚Üì\n",
    "Storage (HDFS / S3 / ADLS)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ Next Deep Dives (Interview Focus)\n",
    "\n",
    "- Narrow vs Wide transformations\n",
    "- Shuffle internals\n",
    "- Join strategies\n",
    "- Spark memory tuning\n",
    "- Performance optimization\n",
    "- Executor tuning parameters\n",
    "- Adaptive Query Execution (AQE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8779b93d-b5f2-499e-a3b7-a62019c88e1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# üöÄ Spark Driver Node vs Worker Node ‚Äî Detailed Architecture (Interview Level)\n",
    "\n",
    "---\n",
    "\n",
    "# 1Ô∏è‚É£ Big Picture: Spark in a Cluster\n",
    "\n",
    "When you submit a Spark job in a distributed cluster (YARN / Kubernetes / Standalone), the architecture looks like this:\n",
    "\n",
    "```\n",
    "                 +-----------------------+\n",
    "                 |      Spark Driver     |\n",
    "                 |  (Brain of App)       |\n",
    "                 +-----------+-----------+\n",
    "                             |\n",
    "               ---------------------------------\n",
    "               |               |               |\n",
    "               v               v               v\n",
    "        +-------------+  +-------------+  +-------------+\n",
    "        |  Executor   |  |  Executor   |  |  Executor   |\n",
    "        | (Worker 1)  |  | (Worker 2)  |  | (Worker N)  |\n",
    "        +-------------+  +-------------+  +-------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 2Ô∏è‚É£ Driver Node (Master of Application)\n",
    "\n",
    "The **Driver** is the brain of the Spark application.\n",
    "\n",
    "It is responsible for:\n",
    "\n",
    "- Creating SparkSession / SparkContext\n",
    "- Building logical plan\n",
    "- Creating DAG\n",
    "- Splitting DAG into stages\n",
    "- Scheduling tasks\n",
    "- Coordinating executors\n",
    "- Collecting results\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Internal Components Inside Driver\n",
    "\n",
    "### 1Ô∏è‚É£ SparkSession\n",
    "Entry point for DataFrame API.\n",
    "\n",
    "### 2Ô∏è‚É£ SparkContext\n",
    "Core connection to cluster manager.\n",
    "\n",
    "### 3Ô∏è‚É£ DAG Scheduler\n",
    "- Converts logical plan into stages\n",
    "- Identifies shuffle boundaries\n",
    "\n",
    "### 4Ô∏è‚É£ Task Scheduler\n",
    "- Sends tasks to executors\n",
    "- Tracks execution\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ What Driver DOES NOT Do\n",
    "\n",
    "- Does NOT process large data\n",
    "- Does NOT execute transformations\n",
    "- Does NOT store partitions\n",
    "\n",
    "Executors handle actual data processing.\n",
    "\n",
    "---\n",
    "\n",
    "# 3Ô∏è‚É£ Driver in Different Deployment Modes\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Client Mode\n",
    "\n",
    "Driver runs on:\n",
    "\n",
    "- Local machine\n",
    "- Edge node\n",
    "- Notebook environment\n",
    "\n",
    "```\n",
    "Client Machine\n",
    "    |\n",
    "    |---- Driver\n",
    "              |\n",
    "              |---- Executors (Cluster)\n",
    "```\n",
    "\n",
    "Risk:\n",
    "If client machine dies ‚Üí Job fails.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Cluster Mode (Production Recommended)\n",
    "\n",
    "Driver runs inside cluster.\n",
    "\n",
    "In YARN:\n",
    "\n",
    "Driver runs inside:\n",
    "\n",
    "üëâ ApplicationMaster container\n",
    "\n",
    "```\n",
    "YARN\n",
    "  |\n",
    "  |-- ApplicationMaster Container\n",
    "          |\n",
    "          |-- Spark Driver\n",
    "```\n",
    "\n",
    "Safer and production-ready.\n",
    "\n",
    "---\n",
    "\n",
    "# 4Ô∏è‚É£ Worker Node (Executor Side)\n",
    "\n",
    "Worker nodes are machines in the cluster that perform computation.\n",
    "\n",
    "Each worker node runs:\n",
    "\n",
    "- NodeManager (in YARN)\n",
    "- One or more Executors\n",
    "- Multiple task threads\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Executor (Inside Worker Node)\n",
    "\n",
    "Executor is:\n",
    "\n",
    "- A JVM process\n",
    "- Allocated memory & cores\n",
    "- Responsible for running tasks\n",
    "\n",
    "Structure:\n",
    "\n",
    "```\n",
    "Worker Node\n",
    "   |\n",
    "   |-- Executor (JVM)\n",
    "          |\n",
    "          |-- Task Thread 1\n",
    "          |-- Task Thread 2\n",
    "          |-- Task Thread 3\n",
    "```\n",
    "\n",
    "Each core = one task at a time.\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ Responsibilities of Executor\n",
    "\n",
    "- Execute tasks\n",
    "- Cache data (if persist used)\n",
    "- Perform shuffle\n",
    "- Write output\n",
    "- Report status back to Driver\n",
    "\n",
    "Executors live for entire application lifetime.\n",
    "\n",
    "---\n",
    "\n",
    "# 5Ô∏è‚É£ Spark on YARN Detailed Architecture\n",
    "\n",
    "```\n",
    "Client submits Spark job\n",
    "        |\n",
    "        v\n",
    "+--------------------------+\n",
    "|   ResourceManager (YARN)|\n",
    "+------------+-------------+\n",
    "             |\n",
    "             v\n",
    "+--------------------------+\n",
    "| ApplicationMaster (AM)  |\n",
    "|  ‚Üí Starts Spark Driver  |\n",
    "+------------+-------------+\n",
    "             |\n",
    "             v\n",
    "+--------------------------+\n",
    "|  NodeManagers (Workers) |\n",
    "|     ‚Üí Launch Executors  |\n",
    "+--------------------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ ApplicationMaster (Important for Interview)\n",
    "\n",
    "In YARN cluster mode:\n",
    "\n",
    "- Spark Driver runs inside ApplicationMaster container.\n",
    "- AM negotiates resources.\n",
    "- Requests executor containers.\n",
    "\n",
    "So:\n",
    "\n",
    "ApplicationMaster = Spark Driver (in cluster mode).\n",
    "\n",
    "---\n",
    "\n",
    "# 6Ô∏è‚É£ Container Concept (YARN Integration)\n",
    "\n",
    "In YARN:\n",
    "\n",
    "- A container = CPU + Memory allocation.\n",
    "- Executors run inside containers.\n",
    "- ApplicationMaster runs inside a container.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "NodeManager 1\n",
    "   |\n",
    "   |-- Container ‚Üí Spark Driver (AM)\n",
    "   |-- Container ‚Üí Executor 1\n",
    "\n",
    "NodeManager 2\n",
    "   |\n",
    "   |-- Container ‚Üí Executor 2\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 7Ô∏è‚É£ Communication Flow\n",
    "\n",
    "```\n",
    "Driver ‚Üí Sends tasks ‚Üí Executors\n",
    "Executors ‚Üí Send results ‚Üí Driver\n",
    "Executors ‚Üí Heartbeat ‚Üí Driver\n",
    "```\n",
    "\n",
    "If executor crashes:\n",
    "\n",
    "- Driver detects failure\n",
    "- Tasks rescheduled\n",
    "- Lost partitions recomputed (RDD lineage)\n",
    "\n",
    "---\n",
    "\n",
    "# 8Ô∏è‚É£ Memory Layout (Executor Side)\n",
    "\n",
    "Executor memory divided into:\n",
    "\n",
    "- Execution Memory (shuffle, join)\n",
    "- Storage Memory (cache)\n",
    "- User Memory\n",
    "- Reserved Memory\n",
    "\n",
    "Misconfiguration leads to:\n",
    "\n",
    "- OOM\n",
    "- Excessive GC\n",
    "- Shuffle spill\n",
    "\n",
    "---\n",
    "\n",
    "# 9Ô∏è‚É£ Failure Scenarios (Interview Favorite)\n",
    "\n",
    "## If Driver Crashes:\n",
    "Entire job fails.\n",
    "\n",
    "## If Executor Crashes:\n",
    "- Only tasks on that executor fail.\n",
    "- Driver reschedules tasks.\n",
    "- Job continues.\n",
    "\n",
    "## If Node Fails:\n",
    "- Containers lost.\n",
    "- Executors relaunched elsewhere.\n",
    "\n",
    "---\n",
    "\n",
    "# üîü Summary Table\n",
    "\n",
    "| Component | Location | Responsibility |\n",
    "|-----------|----------|---------------|\n",
    "| Driver | Master process | Planning & Scheduling |\n",
    "| Executor | Worker Node | Data Processing |\n",
    "| ApplicationMaster | YARN Container | Hosts Driver (cluster mode) |\n",
    "| Container | YARN Resource Unit | Runs Driver or Executor |\n",
    "| NodeManager | Worker Machine | Launches containers |\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Interview-Ready One-Line Explanations\n",
    "\n",
    "Driver:\n",
    "> Coordinates distributed computation but does not process data.\n",
    "\n",
    "Executor:\n",
    "> Performs actual data processing tasks.\n",
    "\n",
    "ApplicationMaster:\n",
    "> YARN component that hosts Spark Driver in cluster mode.\n",
    "\n",
    "Container:\n",
    "> Resource allocation unit in YARN used to run Driver or Executors.\n",
    "\n",
    "---\n",
    "\n",
    "# üöÄ Final Architecture Flow\n",
    "\n",
    "```\n",
    "User Code\n",
    "   ‚Üì\n",
    "Driver (SparkContext + DAG Scheduler)\n",
    "   ‚Üì\n",
    "Cluster Manager (YARN/K8s)\n",
    "   ‚Üì\n",
    "Executors (Worker Nodes)\n",
    "   ‚Üì\n",
    "Tasks (Per Partition)\n",
    "   ‚Üì\n",
    "Data Storage (HDFS/S3/ADLS)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# üî• Deep Dive Next?\n",
    "\n",
    "We can now go into:\n",
    "\n",
    "- Shuffle internals (how data physically moves)\n",
    "- Narrow vs Wide transformations\n",
    "- Join strategies (Broadcast vs SortMerge vs Shuffle)\n",
    "- Memory tuning parameters\n",
    "- Adaptive Query Execution (AQE)\n",
    "- Executor tuning for interviews\n",
    "\n",
    "Tell me which one you want next üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdcad2d3-c9a0-445e-8cb2-99fecb089176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62f62165-0367-40ef-bcad-f86d41817f62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98e4aa5b-6321-42d5-b4c8-b0ec9f7386ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c88d53a-740c-4b3a-936b-46e03da1e649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18a03add-16a4-4e27-976a-21bc1228758c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d238f6f0-ce08-4fb0-93cc-3e521bc13f66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d70f2067-32c5-4144-8981-6319c289201a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# üéØ Next Smart Step (Based on Your Learning Path)\n",
    "\n",
    "Since you're preparing seriously for distributed data engineering:\n",
    "\n",
    "You should now move to:\n",
    "```\n",
    "1Ô∏è‚É£ Spark architecture\n",
    "2Ô∏è‚É£ RDD vs DataFrame vs Dataset\n",
    "3Ô∏è‚É£ DAG vs MapReduce\n",
    "4Ô∏è‚É£ Spark execution flow\n",
    "5Ô∏è‚É£ Spark on YARN\n",
    "\n",
    "```\n",
    "\n",
    "## You‚Äôre Now Ready For:\n",
    "\n",
    "- Deep Spark architecture\n",
    "- Distributed join explanation\n",
    "- Shuffle internals\n",
    "- Partitioning strategies\n",
    "- Performance tuning\n",
    "\n",
    "\n",
    "**If you want next, I can:**\n",
    "\n",
    "- Show internal progress calculation logic\n",
    "- Explain how Spark handles stragglers\n",
    "- Explain speculative execution in Spark\n",
    "- Or give you tricky interview scenarios"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "01-Spark & Distributed Data Basics",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
